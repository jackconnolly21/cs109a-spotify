{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoders Testing\n",
    "Trying out the feasibility of variational autoencoders for music recommender systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Data Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example entry in a playlist file:\n",
    "\n",
    "```\n",
    "\"info\": {\n",
    "        \"generated_on\": \"2017-12-03 08:41:42.057563\", \n",
    "        \"slice\": \"0-999\", \n",
    "        \"version\": \"v1\"\n",
    "    }, \n",
    "\"playlists\": [\n",
    "    {\n",
    "        \"name\": \"Throwbacks\", \n",
    "        \"collaborative\": \"false\", \n",
    "        \"pid\": 0, \n",
    "        \"modified_at\": 1493424000, \n",
    "        \"num_tracks\": 52, \n",
    "        \"num_albums\": 47, \n",
    "        \"num_followers\": 1, \n",
    "        \"tracks\": [\n",
    "            {\n",
    "                \"pos\": 0, \n",
    "                \"artist_name\": \"Missy Elliott\", \n",
    "                \"track_uri\": \"spotify:track:0UaMYEvWZi0ZqiDOoHU3YI\", \n",
    "                \"artist_uri\": \"spotify:artist:2wIVse2owClT7go1WT98tk\", \n",
    "                \"track_name\": \"Lose Control (feat. Ciara & Fat Man Scoop)\", \n",
    "                \"album_uri\": \"spotify:album:6vV5UrXcfyQD1wu4Qo2I9K\", \n",
    "                \"duration_ms\": 226863, \n",
    "                \"album_name\": \"The Cookbook\"\n",
    "            }, \n",
    "            ...\n",
    "         ],\n",
    "        \"num_edits\": 6, \n",
    "        \"duration_ms\": 11532414, \n",
    "        \"num_artists\": 37\n",
    "     }, \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'large_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading file 0\n",
      "done loading file 1\n",
      "done loading file 2\n",
      "done loading file 3\n",
      "done loading file 4\n",
      "done loading file 5\n",
      "done loading file 6\n",
      "done loading file 7\n",
      "done loading file 8\n",
      "done loading file 9\n"
     ]
    }
   ],
   "source": [
    "f_start = 0\n",
    "f_end = 999\n",
    "num_files = 10\n",
    "counter = 0\n",
    "\n",
    "track_codes = {}\n",
    "track_counts = {}\n",
    "playlists = []\n",
    "\n",
    "for i in range(num_files) : \n",
    "    with open(data_path + '/mpd.slice.{}-{}.json'.format(f_start, f_end)) as f : \n",
    "        data = json.load(f)\n",
    "        \n",
    "    for playlist in data['playlists'] : \n",
    "        playlist_dict = playlist.copy()\n",
    "        playlist_dict.pop('tracks', None)\n",
    "        \n",
    "        for song in playlist['tracks'] : \n",
    "            track_name  = song['track_name']\n",
    "            track_uri = song['track_uri']\n",
    "            \n",
    "            if track_name not in track_counts:\n",
    "                track_counts[track_name] = 0\n",
    "                \n",
    "            if track_name not in track_codes:\n",
    "                track_codes[track_name] = counter\n",
    "                counter += 1\n",
    "                \n",
    "            track_counts[track_name] += 1\n",
    "        \n",
    "        last_song = playlist['tracks'][-1]['track_name']\n",
    "        playlist_dict['last_song'] = track_codes[last_song]\n",
    "#         playlist_dict['last_song'] = last_song\n",
    "        \n",
    "        playlists.append(playlist_dict)\n",
    "            \n",
    "    print (\"done loading file\", i)             \n",
    "    f_start += 1000\n",
    "    f_end += 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playlist_df = pd.DataFrame(playlists)\n",
    "playlist_df = playlist_df.drop(['description', 'collaborative'], axis=1)\n",
    "\n",
    "enc = sklearn.preprocessing.LabelBinarizer()\n",
    "last_songs = enc.fit_transform(playlist_df['last_song'])\n",
    "\n",
    "train_df, test_df, y_train, y_test = train_test_split(playlist_df, last_songs, test_size=0.2, random_state=836)\n",
    "X_train = train_df.drop(['name', 'pid', 'last_song'], axis=1)\n",
    "X_test = test_df.drop(['name', 'pid', 'last_song'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>modified_at</th>\n",
       "      <th>num_albums</th>\n",
       "      <th>num_artists</th>\n",
       "      <th>num_edits</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>9898463</td>\n",
       "      <td>1429488000</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6528</th>\n",
       "      <td>6846312</td>\n",
       "      <td>1459555200</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4290</th>\n",
       "      <td>11655830</td>\n",
       "      <td>1507680000</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9077152</td>\n",
       "      <td>1509408000</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>13706751</td>\n",
       "      <td>1473033600</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      duration_ms  modified_at  num_albums  num_artists  num_edits  \\\n",
       "9753      9898463   1429488000          39           35          4   \n",
       "6528      6846312   1459555200          28           19         12   \n",
       "4290     11655830   1507680000          44           31         45   \n",
       "22        9077152   1509408000          39           37         15   \n",
       "3878     13706751   1473033600          33           11          5   \n",
       "\n",
       "      num_followers  num_tracks  cluster  \n",
       "9753              1          41        1  \n",
       "6528              1          30        3  \n",
       "4290              1          50        4  \n",
       "22                2          42        4  \n",
       "3878              5          67        3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=10)\n",
    "clusters =km.fit_predict(X_train)\n",
    "X_train['cluster'] = clusters\n",
    "X_test['cluster'] = km.predict(X_test)\n",
    "\n",
    "display(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding (For names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = {}\n",
    "count = 0\n",
    "for name in train_df['name']:\n",
    "    if name not in names:\n",
    "        names[name] = count\n",
    "        count += 1\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_model = Sequential()\n",
    "embed_model.add(Embedding(5000, 16, input_length=1))\n",
    "embed_model.compile('rmsprop', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_ids = train_df['name'].apply(lambda n: names[n])\n",
    "embeddings = embed_model.predict(name_ids)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model (Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "softmax() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-15d1fa67bb0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda/envs/cs109/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/Library/anaconda/envs/cs109/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda/envs/cs109/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda/envs/cs109/lib/python3.6/site-packages/keras/activations.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot apply softmax to a tensor that is 1D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda/envs/cs109/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m   3229\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3230\u001b[0m     \"\"\"\n\u001b[0;32m-> 3231\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Dense(hidden_size, input_dim=input_dim, activation='relu'))\n",
    "model1.add(Dense(hidden_size, activation='relu'))\n",
    "model1.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "model1.compile(optimizer='adam', loss='mae', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 4s 583us/step - loss: 429436.9298 - acc: 0.0000e+00 - val_loss: 63857.9077 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 3s 535us/step - loss: 45536.1081 - acc: 1.5625e-04 - val_loss: 32619.8276 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 4s 558us/step - loss: 22334.3727 - acc: 0.0000e+00 - val_loss: 16096.9139 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 3s 544us/step - loss: 15821.8652 - acc: 1.5625e-04 - val_loss: 23629.1957 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 4s 611us/step - loss: 4727.5059 - acc: 1.5625e-04 - val_loss: 2.5982e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 4s 562us/step - loss: 2.5819e-04 - acc: 1.5625e-04 - val_loss: 2.5594e-04 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 4s 566us/step - loss: 2.5312e-04 - acc: 0.0000e+00 - val_loss: 2.5129e-04 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 4s 569us/step - loss: 2.4889e-04 - acc: 0.0000e+00 - val_loss: 2.4732e-04 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 4s 583us/step - loss: 2.4683e-04 - acc: 1.5625e-04 - val_loss: 2.4474e-04 - val_acc: 6.2500e-04\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 4s 568us/step - loss: 2.4546e-04 - acc: 0.0000e+00 - val_loss: 2.4551e-04 - val_acc: 6.2500e-04\n"
     ]
    }
   ],
   "source": [
    "model1_history = model1.fit(X_train, y_train, batch_size=32, \n",
    "                            epochs=10, verbose=1, \n",
    "                            shuffle = True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 157us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00024550651805475355, 0.0]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN/LSTM attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(output_dim, hidden_size, input_length=input_len))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "#model.add(LSTM(hidden_size, return_sequences=True))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(TimeDistributed(Dense(output_dim, activation='softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "class Evaluator():\n",
    "    \"\"\"Superclass for evaluation functions\"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def evaluate(self, output, expected):\n",
    "        \"\"\"\n",
    "        Output will be the output of the model for some list of playlists\n",
    "        - Shape of (# playlists, 500)\n",
    "\n",
    "        Expected will be the held out songs from each playlist\n",
    "        - List of lists of various sizes\n",
    "\n",
    "        Note: Each \"song\" will be the unique spotify uri of a song\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "        \n",
    "def RPrecision(Evaluator):\n",
    "    \"\"\"\n",
    "    R-precision measures the number of held out songs correctly \n",
    "        retrieved by the model output \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        Evaluator.__init__(self, 'R-Precision')\n",
    "        \n",
    "    def evaluate(self, output, expected):\n",
    "    \n",
    "        def rprec_one(output_, expected_):\n",
    "            expected_size = len(expected_)\n",
    "            common_set = set(output_).intersection(set(expected_))\n",
    "            common_size = len(common_set)\n",
    "            return common_size / expected_size\n",
    "        \n",
    "        return np.mean([rprec_one(out, exp) for (out, exp) in zip(output, expected)])\n",
    "\n",
    "    \n",
    "def NDCG(Evaluator):\n",
    "    \"\"\"\n",
    "    Normalized discounted cumulative gain also takes into \n",
    "        account how the system ordered the suggestions\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        Evaluator.__init__(self, 'NDCG')\n",
    "        \n",
    "    def evaluate(self, output, expected):\n",
    "        \n",
    "        def ndcg_one(output_, expected_):\n",
    "            dcg, idcg = 0.0, 0.0\n",
    "\n",
    "            for i in range(len(output_)):\n",
    "                # Prediction DCG\n",
    "                if output_[i] in expected_:\n",
    "                    if i == 0:\n",
    "                        dcg += 1.0\n",
    "                    else:\n",
    "                        dcg += 1.0 / log2(i + 2.0)\n",
    "\n",
    "                if i < len(expected_):\n",
    "                    if i == 0:\n",
    "                        idcg += 1.0\n",
    "                    else:\n",
    "                        idcg += 1.0 / log(i + 2.0)\n",
    "\n",
    "            return dcg / idcg\n",
    "        \n",
    "        return np.mean([ndcg_one(out, exp) for (out, exp) in zip(output, expected)])\n",
    "        \n",
    "        \n",
    "def RSC(Evaluator):\n",
    "    \"\"\"\n",
    "    Recommended Song Clicks measures how many times a user\n",
    "    would have to click through the suggestions to find a song that \n",
    "    was a ground truth song\n",
    "    \"\"\"\n",
    "    def __init__():\n",
    "        Evaluator.__init__(self, 'RSC')\n",
    "        \n",
    "    def evaluate(self, output, expected):\n",
    "        \n",
    "        def rsc_one(output_, expected_):   \n",
    "            output_len = len(output)\n",
    "            for i in range(output_len):\n",
    "                if output[i] in expected:\n",
    "                    return i//10\n",
    "            return 51\n",
    "        \n",
    "        return np.mean([rsc_one(out, exp) for (out, exp) in zip(output, expected)])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS 109",
   "language": "python",
   "name": "cs109"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
