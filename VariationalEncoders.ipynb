{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoders Testing\n",
    "Trying out the feasibility of variational autoencoders for music recommender systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Data Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example entry in a playlist file:\n",
    "\n",
    "```\n",
    "\"info\": {\n",
    "        \"generated_on\": \"2017-12-03 08:41:42.057563\", \n",
    "        \"slice\": \"0-999\", \n",
    "        \"version\": \"v1\"\n",
    "    }, \n",
    "\"playlists\": [\n",
    "    {\n",
    "        \"name\": \"Throwbacks\", \n",
    "        \"collaborative\": \"false\", \n",
    "        \"pid\": 0, \n",
    "        \"modified_at\": 1493424000, \n",
    "        \"num_tracks\": 52, \n",
    "        \"num_albums\": 47, \n",
    "        \"num_followers\": 1, \n",
    "        \"tracks\": [\n",
    "            {\n",
    "                \"pos\": 0, \n",
    "                \"artist_name\": \"Missy Elliott\", \n",
    "                \"track_uri\": \"spotify:track:0UaMYEvWZi0ZqiDOoHU3YI\", \n",
    "                \"artist_uri\": \"spotify:artist:2wIVse2owClT7go1WT98tk\", \n",
    "                \"track_name\": \"Lose Control (feat. Ciara & Fat Man Scoop)\", \n",
    "                \"album_uri\": \"spotify:album:6vV5UrXcfyQD1wu4Qo2I9K\", \n",
    "                \"duration_ms\": 226863, \n",
    "                \"album_name\": \"The Cookbook\"\n",
    "            }, \n",
    "            ...\n",
    "         ],\n",
    "        \"num_edits\": 6, \n",
    "        \"duration_ms\": 11532414, \n",
    "        \"num_artists\": 37\n",
    "     }, \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'large_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading file 0\n",
      "done loading file 1\n",
      "done loading file 2\n",
      "done loading file 3\n",
      "done loading file 4\n",
      "done loading file 5\n",
      "done loading file 6\n",
      "done loading file 7\n",
      "done loading file 8\n",
      "done loading file 9\n"
     ]
    }
   ],
   "source": [
    "f_start = 0\n",
    "f_end = 999\n",
    "num_files = 10\n",
    "counter = 0\n",
    "\n",
    "track_codes = {}\n",
    "track_counts = {}\n",
    "playlists = []\n",
    "\n",
    "for i in range(num_files) : \n",
    "    with open(data_path + '/mpd.slice.{}-{}.json'.format(f_start, f_end)) as f : \n",
    "        data = json.load(f)\n",
    "        \n",
    "    for playlist in data['playlists'] : \n",
    "        playlist_dict = playlist.copy()\n",
    "        playlist_dict.pop('tracks', None)\n",
    "        \n",
    "        for song in playlist['tracks'] : \n",
    "            track_name  = song['track_name']\n",
    "            track_uri = song['track_uri']\n",
    "            \n",
    "            if track_name not in track_counts:\n",
    "                track_counts[track_name] = 0\n",
    "                \n",
    "            if track_name not in track_codes:\n",
    "                track_codes[track_name] = counter\n",
    "                counter += 1\n",
    "                \n",
    "            track_counts[track_name] += 1\n",
    "        \n",
    "        last_song = playlist['tracks'][-1]['track_name']\n",
    "        playlist_dict['last_song'] = track_codes[last_song]\n",
    "#         playlist_dict['last_song'] = last_song\n",
    "        \n",
    "        playlists.append(playlist_dict)\n",
    "            \n",
    "    print (\"done loading file\", i)             \n",
    "    f_start += 1000\n",
    "    f_end += 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_df = pd.DataFrame(playlists)\n",
    "playlist_df = playlist_df.drop(['description', 'collaborative'], axis=1)\n",
    "\n",
    "enc = sklearn.preprocessing.LabelBinarizer()\n",
    "last_songs = enc.fit_transform(playlist_df['last_song'])\n",
    "\n",
    "train_df, test_df, y_train, y_test = train_test_split(playlist_df, last_songs, test_size=0.2, random_state=836)\n",
    "X_train = train_df.drop(['name', 'pid', 'last_song'], axis=1)\n",
    "X_test = test_df.drop(['name', 'pid', 'last_song'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>modified_at</th>\n",
       "      <th>num_albums</th>\n",
       "      <th>num_artists</th>\n",
       "      <th>num_edits</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>9898463</td>\n",
       "      <td>1429488000</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6528</th>\n",
       "      <td>6846312</td>\n",
       "      <td>1459555200</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4290</th>\n",
       "      <td>11655830</td>\n",
       "      <td>1507680000</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9077152</td>\n",
       "      <td>1509408000</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>13706751</td>\n",
       "      <td>1473033600</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      duration_ms  modified_at  num_albums  num_artists  num_edits  \\\n",
       "9753      9898463   1429488000          39           35          4   \n",
       "6528      6846312   1459555200          28           19         12   \n",
       "4290     11655830   1507680000          44           31         45   \n",
       "22        9077152   1509408000          39           37         15   \n",
       "3878     13706751   1473033600          33           11          5   \n",
       "\n",
       "      num_followers  num_tracks  cluster  \n",
       "9753              1          41        1  \n",
       "6528              1          30        3  \n",
       "4290              1          50        4  \n",
       "22                2          42        4  \n",
       "3878              5          67        3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=10)\n",
    "clusters =km.fit_predict(X_train)\n",
    "X_train['cluster'] = clusters\n",
    "X_test['cluster'] = km.predict(X_test)\n",
    "\n",
    "display(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding (For names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {}\n",
    "count = 0\n",
    "for name in train_df['name']:\n",
    "    if name not in names:\n",
    "        names[name] = count\n",
    "        count += 1\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_model = Sequential()\n",
    "embed_model.add(Embedding(5000, 16, input_length=1))\n",
    "embed_model.compile('rmsprop', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_ids = train_df['name'].apply(lambda n: names[n])\n",
    "embeddings = embed_model.predict(name_ids)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model (Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Dense(hidden_size, input_dim=input_dim, activation='relu'))\n",
    "model1.add(Dense(hidden_size, activation='relu'))\n",
    "model1.add(Dense(output_dim, activation='linear'))\n",
    "\n",
    "model1.compile(optimizer='adam', loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 4s 629us/step - loss: 444891.9355 - val_loss: 78116.3559\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 3s 515us/step - loss: 62679.8393 - val_loss: 50266.9962\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 3s 529us/step - loss: 41786.8608 - val_loss: 30751.4893\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 3s 526us/step - loss: 27214.7743 - val_loss: 20607.8004\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 3s 523us/step - loss: 18745.3708 - val_loss: 16950.2534\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 3s 524us/step - loss: 14255.1074 - val_loss: 8973.4102\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 3s 532us/step - loss: 17849.8867 - val_loss: 15221.9489\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 3s 525us/step - loss: 10465.1087 - val_loss: 0.0017\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 3s 528us/step - loss: 3.5304e-04 - val_loss: 2.5659e-04\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 3s 530us/step - loss: 2.5430e-04 - val_loss: 2.5214e-04\n"
     ]
    }
   ],
   "source": [
    "model1_history = model1.fit(X_train, y_train, batch_size=32, \n",
    "                            epochs=10, verbose=1, \n",
    "                            shuffle = True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 152us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00025214326265268029"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN/LSTM attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(output_dim, hidden_size, input_length=input_len))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "#model.add(LSTM(hidden_size, return_sequences=True))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(TimeDistributed(Dense(output_dim, activation='softmax')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS 109",
   "language": "python",
   "name": "cs109"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
