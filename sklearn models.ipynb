{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Model\n",
    "VAEs are not going to be reasonable. Testing out some sklearn models as baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spotipy\n",
    "import pickle\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Data Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example entry in a playlist file:\n",
    "\n",
    "```\n",
    "\"info\": {\n",
    "        \"generated_on\": \"2017-12-03 08:41:42.057563\", \n",
    "        \"slice\": \"0-999\", \n",
    "        \"version\": \"v1\"\n",
    "    }, \n",
    "\"playlists\": [\n",
    "    {\n",
    "        \"name\": \"Throwbacks\", \n",
    "        \"collaborative\": \"false\", \n",
    "        \"pid\": 0, \n",
    "        \"modified_at\": 1493424000, \n",
    "        \"num_tracks\": 52, \n",
    "        \"num_albums\": 47, \n",
    "        \"num_followers\": 1, \n",
    "        \"tracks\": [\n",
    "            {\n",
    "                \"pos\": 0, \n",
    "                \"artist_name\": \"Missy Elliott\", \n",
    "                \"track_uri\": \"spotify:track:0UaMYEvWZi0ZqiDOoHU3YI\", \n",
    "                \"artist_uri\": \"spotify:artist:2wIVse2owClT7go1WT98tk\", \n",
    "                \"track_name\": \"Lose Control (feat. Ciara & Fat Man Scoop)\", \n",
    "                \"album_uri\": \"spotify:album:6vV5UrXcfyQD1wu4Qo2I9K\", \n",
    "                \"duration_ms\": 226863, \n",
    "                \"album_name\": \"The Cookbook\"\n",
    "            }, \n",
    "            ...\n",
    "         ],\n",
    "        \"num_edits\": 6, \n",
    "        \"duration_ms\": 11532414, \n",
    "        \"num_artists\": 37\n",
    "     }, \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'large_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading file 0\n",
      "done loading file 1\n",
      "done loading file 2\n",
      "done loading file 3\n",
      "done loading file 4\n",
      "done loading file 5\n",
      "done loading file 6\n",
      "done loading file 7\n",
      "done loading file 8\n",
      "done loading file 9\n"
     ]
    }
   ],
   "source": [
    "f_start = 0\n",
    "f_end = 999\n",
    "num_files = 10\n",
    "counter = 0\n",
    "K = 25\n",
    "\n",
    "track_codes = {}\n",
    "track_counts = {}\n",
    "playlists = []\n",
    "uri_input, uri_expected = [], []\n",
    "\n",
    "for i in range(num_files) : \n",
    "    with open(data_path + '/mpd.slice.{}-{}.json'.format(f_start, f_end)) as f : \n",
    "        data = json.load(f)\n",
    "        \n",
    "    for playlist in data['playlists']: \n",
    "        playlist_dict = playlist.copy()\n",
    "        playlist_dict.pop('tracks', None)\n",
    "        \n",
    "        input_, expected = [], []\n",
    "        for k, song in enumerate(playlist['tracks']):\n",
    "            track_name  = song['track_name']\n",
    "            track_uri = song['track_uri']\n",
    "            \n",
    "            if track_uri not in track_counts:\n",
    "                track_counts[track_uri] = 0\n",
    "                \n",
    "            if track_uri not in track_codes:\n",
    "                track_codes[track_uri] = counter\n",
    "                counter += 1\n",
    "                \n",
    "            track_counts[track_uri] += 1\n",
    "            \n",
    "            if k < K:\n",
    "                input_.append(track_uri)\n",
    "            else:\n",
    "                expected.append(track_uri)\n",
    "        \n",
    "        last_song = playlist['tracks'][-1]['track_uri']\n",
    "        playlist_dict['last_song'] = track_codes[last_song]\n",
    "        \n",
    "        playlists.append(playlist_dict)\n",
    "        uri_input.append(input_)\n",
    "        uri_expected.append(expected)\n",
    "            \n",
    "    print (\"done loading file\", i)             \n",
    "    f_start += 1000\n",
    "    f_end += 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playlist_df = pd.DataFrame(playlists)\n",
    "playlist_df = playlist_df.drop(['description', 'collaborative'], axis=1)\n",
    "\n",
    "enc = sklearn.preprocessing.LabelBinarizer()\n",
    "last_songs = enc.fit_transform(playlist_df['last_song'])\n",
    "\n",
    "train_df, test_df, y_train, y_test = train_test_split(playlist_df, last_songs, test_size=0.2, random_state=836)\n",
    "X_train = train_df.drop(['name', 'pid', 'last_song'], axis=1)\n",
    "X_test = test_df.drop(['name', 'pid', 'last_song'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "AttributeError\n",
      "Start: 115800\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n"
     ]
    }
   ],
   "source": [
    "uris = list(track_codes.keys())\n",
    "spotify = spotipy.Spotify(auth='BQCS0mGrYXNtoVfeXJtjJC64CGcH1D_hsZrpTbVt2x4SUB5O9T978bBs20xuJSiw3lRyFWoz80sMqD1A2tQP5kOQPTMBbrsMg5tn5Wi4DnI9l_LgLdfGzmrdDC83Yiok4kuayNzrUcCC3hHzZHUVlyWCk9taB7z2eo3ssw')\n",
    "\n",
    "keys_to_remove = [\"duration_ms\", \"type\", \"id\", \"uri\", \"track_href\", \"analysis_url\"]\n",
    "\n",
    "start = 0\n",
    "audio_features = []\n",
    "while start < len(uris):\n",
    "    try:\n",
    "        response = spotify.audio_features(uris[start:(100+start)])\n",
    "        small_response = [{key:track[key] for key in track.keys() - keys_to_remove} for track in response]\n",
    "        audio_features.extend(small_response)\n",
    "    except AttributeError:\n",
    "        print(\"AttributeError\")\n",
    "        print(\"Start:\", start)\n",
    "    start += 100\n",
    "    if start % 1000 == 0: print(start)\n",
    "\n",
    "audio_df = pd.DataFrame(audio_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('audio_features.pickle', 'wb') as handle:\n",
    "    pickle.dump(audio_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering songs together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(uri_input, uri_expected, test_size=.2, random_state=431)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features in audio_df to mean=0 and variance=1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "audio_scaled = ss.fit_transform(audio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster songs and build dict with list of URIs for each cluster\n",
    "n_clusters = 20\n",
    "km_songs = KMeans(n_clusters=n_clusters)\n",
    "song_clusters = km_songs.fit_predict(audio_scaled)\n",
    "\n",
    "cluster_to_songs, song_to_cluster = {}, {}\n",
    "for i, cluster_num in enumerate(song_clusters):\n",
    "    if cluster_num not in cluster_to_songs:\n",
    "        cluster_to_songs[cluster_num] = []\n",
    "        \n",
    "    cluster_to_songs[cluster_num].append(uris[i])\n",
    "    song_to_cluster[uris[i]] = cluster_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClusterModel:\n",
    "    def __init__(self, cluster_to_song, song_to_cluster, n_clusters=20, K=25):\n",
    "        self.name = 'cluster_model'\n",
    "        self.n_clusters = n_clusters\n",
    "        self.cluster_to_song = cluster_to_song\n",
    "        self.song_to_cluster = song_to_cluster\n",
    "        self.K = K\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for playlist in X:\n",
    "            clusters = [self.song_to_cluster[song] for song in playlist if song in self.song_to_cluster]\n",
    "            unique, counts = np.unique(clusters, return_counts=True)\n",
    "            max_cluster_id = unique[np.argmax(counts)]\n",
    "            max_cluster = self.cluster_to_song[max_cluster_id]\n",
    "            predicted = np.random.choice(max_cluster, size=500, replace=False)\n",
    "            predictions.append(predicted)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = ClusterModel(cluster_to_songs, song_to_cluster)\n",
    "cm.fit(X_train_c, y_train_c)\n",
    "cm_output = cm.predict(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00580806560947 0.00290581392781 32.437\n"
     ]
    }
   ],
   "source": [
    "# Evaluation with the metrics\n",
    "r_prec = RPrecision().evaluate(cm_output, y_test_c)\n",
    "ndcg = NDCG().evaluate(cm_output, y_test_c)\n",
    "rsc = RSC().evaluate(cm_output, y_test_c)\n",
    "print(r_prec, ndcg, rsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model (Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Dense(hidden_size, input_dim=input_dim, activation='relu'))\n",
    "model1.add(Dense(hidden_size, activation='relu'))\n",
    "model1.add(Dense(output_dim, activation='linear'))\n",
    "\n",
    "model1.compile(optimizer='adam', loss='mae', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_history = model1.fit(X_train, y_train, batch_size=32, \n",
    "                            epochs=10, verbose=1, \n",
    "                            shuffle = True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "class Evaluator():\n",
    "    \"\"\"Superclass for evaluation functions\"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def evaluate(self, output, expected):\n",
    "        \"\"\"\n",
    "        Output will be the output of the model for some list of playlists\n",
    "        - Shape of (# playlists, 500)\n",
    "\n",
    "        Expected will be the held out songs from each playlist\n",
    "        - List of lists of various sizes\n",
    "\n",
    "        Note: Each \"song\" will be the unique spotify uri of a song\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "        \n",
    "class RPrecision(Evaluator):\n",
    "    \"\"\"\n",
    "    R-precision measures the number of held out songs correctly \n",
    "        retrieved by the model output \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        Evaluator.__init__(self, 'R-Precision')\n",
    "        \n",
    "    def evaluate(self, output, expected):\n",
    "    \n",
    "        def rprec_one(output_, expected_):\n",
    "            expected_size = len(expected_)\n",
    "            common_set = set(output_).intersection(set(expected_))\n",
    "            common_size = len(common_set)\n",
    "            if expected_size == 0 or common_size == 0:\n",
    "                return 0.0\n",
    "            return common_size / expected_size\n",
    "        \n",
    "        return np.mean([rprec_one(out, exp) for (out, exp) in zip(output, expected)])\n",
    "\n",
    "    \n",
    "class NDCG(Evaluator):\n",
    "    \"\"\"\n",
    "    Normalized discounted cumulative gain also takes into \n",
    "        account how the system ordered the suggestions\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        Evaluator.__init__(self, 'NDCG')\n",
    "        \n",
    "    def evaluate(self, output, expected):\n",
    "        \n",
    "        def ndcg_one(output_, expected_):\n",
    "            dcg, idcg = 0.0, 0.0\n",
    "            \n",
    "            if len(output_) == 0 or len(expected_) == 0:\n",
    "                return 0.0\n",
    "\n",
    "            for i in range(len(output_)):\n",
    "                # Prediction DCG\n",
    "                if output_[i] in expected_:\n",
    "                    if i == 0:\n",
    "                        dcg += 1.0\n",
    "                    else:\n",
    "                        dcg += 1.0 / log2(i + 2.0)\n",
    "\n",
    "                if i < len(expected_):\n",
    "                    if i == 0:\n",
    "                        idcg += 1.0\n",
    "                    else:\n",
    "                        idcg += 1.0 / log2(i + 2.0)\n",
    "            \n",
    "            return dcg / idcg\n",
    "        \n",
    "        return np.mean([ndcg_one(out, exp) for (out, exp) in zip(output, expected)])\n",
    "        \n",
    "        \n",
    "class RSC(Evaluator):\n",
    "    \"\"\"\n",
    "    Recommended Song Clicks measures how many times a user\n",
    "    would have to click through the suggestions to find a song that \n",
    "    was a ground truth song\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        Evaluator.__init__(self, 'RSC')\n",
    "        \n",
    "    def evaluate(self, output, expected):\n",
    "        \n",
    "        def rsc_one(output_, expected_):\n",
    "            if len(output_) == 0 or len(expected_) == 0:\n",
    "                return 0.0\n",
    "            \n",
    "            output_len = len(output_)\n",
    "            for i in range(output_len):\n",
    "                if output_[i] in expected_:\n",
    "                    return i//10\n",
    "            return 51\n",
    "        \n",
    "        return np.mean([rsc_one(out, exp) for (out, exp) in zip(output, expected)])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS 109",
   "language": "python",
   "name": "cs109"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
