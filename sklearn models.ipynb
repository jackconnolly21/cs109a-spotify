{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models and Data Engineering\n",
    "Doing some EDA, data engineering and testing out some simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spotipy\n",
    "import pickle\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Data Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example entry in a playlist file:\n",
    "\n",
    "```\n",
    "\"info\": {\n",
    "        \"generated_on\": \"2017-12-03 08:41:42.057563\", \n",
    "        \"slice\": \"0-999\", \n",
    "        \"version\": \"v1\"\n",
    "    }, \n",
    "\"playlists\": [\n",
    "    {\n",
    "        \"name\": \"Throwbacks\", \n",
    "        \"collaborative\": \"false\", \n",
    "        \"pid\": 0, \n",
    "        \"modified_at\": 1493424000, \n",
    "        \"num_tracks\": 52, \n",
    "        \"num_albums\": 47, \n",
    "        \"num_followers\": 1, \n",
    "        \"tracks\": [\n",
    "            {\n",
    "                \"pos\": 0, \n",
    "                \"artist_name\": \"Missy Elliott\", \n",
    "                \"track_uri\": \"spotify:track:0UaMYEvWZi0ZqiDOoHU3YI\", \n",
    "                \"artist_uri\": \"spotify:artist:2wIVse2owClT7go1WT98tk\", \n",
    "                \"track_name\": \"Lose Control (feat. Ciara & Fat Man Scoop)\", \n",
    "                \"album_uri\": \"spotify:album:6vV5UrXcfyQD1wu4Qo2I9K\", \n",
    "                \"duration_ms\": 226863, \n",
    "                \"album_name\": \"The Cookbook\"\n",
    "            }, \n",
    "            ...\n",
    "         ],\n",
    "        \"num_edits\": 6, \n",
    "        \"duration_ms\": 11532414, \n",
    "        \"num_artists\": 37\n",
    "     }, \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'large_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading file 0\n",
      "done loading file 1\n",
      "done loading file 2\n",
      "done loading file 3\n",
      "done loading file 4\n",
      "done loading file 5\n",
      "done loading file 6\n",
      "done loading file 7\n",
      "done loading file 8\n",
      "done loading file 9\n"
     ]
    }
   ],
   "source": [
    "f_start = 0\n",
    "f_end = 999\n",
    "num_files = 10\n",
    "counter = 0\n",
    "K = 25\n",
    "\n",
    "track_codes = {}\n",
    "track_counts = {}\n",
    "playlists = []\n",
    "uri_input, uri_expected = [], []\n",
    "\n",
    "for i in range(num_files) : \n",
    "    with open(data_path + '/mpd.slice.{}-{}.json'.format(f_start, f_end)) as f : \n",
    "        data = json.load(f)\n",
    "        \n",
    "    for playlist in data['playlists']: \n",
    "        playlist_dict = playlist.copy()\n",
    "        playlist_dict.pop('tracks', None)\n",
    "        \n",
    "        input_, expected = [], []\n",
    "        for k, song in enumerate(playlist['tracks']):\n",
    "            track_name  = song['track_name']\n",
    "            track_uri = song['track_uri']\n",
    "            \n",
    "            if track_uri not in track_counts:\n",
    "                track_counts[track_uri] = 0\n",
    "                \n",
    "            if track_uri not in track_codes:\n",
    "                track_codes[track_uri] = counter\n",
    "                counter += 1\n",
    "                \n",
    "            track_counts[track_uri] += 1\n",
    "            \n",
    "            if k < K:\n",
    "                input_.append(track_uri)\n",
    "            else:\n",
    "                expected.append(track_uri)\n",
    "        \n",
    "        last_song = playlist['tracks'][-1]['track_uri']\n",
    "        playlist_dict['last_song'] = track_codes[last_song]\n",
    "        \n",
    "        playlists.append(playlist_dict)\n",
    "        uri_input.append(input_)\n",
    "        uri_expected.append(expected)\n",
    "            \n",
    "    print (\"done loading file\", i)             \n",
    "    f_start += 1000\n",
    "    f_end += 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playlist_df = pd.DataFrame(playlists)\n",
    "playlist_df = playlist_df.drop(['description', 'collaborative'], axis=1)\n",
    "\n",
    "enc = sklearn.preprocessing.LabelBinarizer()\n",
    "last_songs = enc.fit_transform(playlist_df['last_song'])\n",
    "\n",
    "train_df, test_df, y_train, y_test = train_test_split(playlist_df, last_songs, test_size=0.2, random_state=836)\n",
    "X_train = train_df.drop(['name', 'pid', 'last_song'], axis=1)\n",
    "X_test = test_df.drop(['name', 'pid', 'last_song'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting audio features from the Spotify API\n",
    "This takes awhile to run - just load the 'audio_features.pickle' file instead\n",
    "Also note that uris[115873] for some reason returning None for audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "AttributeError\n",
      "Start: 115800\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n"
     ]
    }
   ],
   "source": [
    "uris = list(track_codes.keys())\n",
    "spotify = spotipy.Spotify(auth='BQDuG3_3-tAv09LQlZKwYc-oodCcDdau9O-I-Ep_O6IK-Uqvc5S3FKwdr5qtVu5Kq1khJCwkeaR9PnQJjvL6fBRPWdjJ9H_KRoGCrSlMP5DjdcLMlWJybPF1VvJDuSwBpoxiLS_Qmr9R4z-RoDWDPNiZnlzCeJNxMMvLRg')\n",
    "\n",
    "keys_to_remove = [\"duration_ms\", \"type\", \"id\", \"uri\", \"track_href\", \"analysis_url\"]\n",
    "\n",
    "start = 0\n",
    "audio_features = []\n",
    "while start < len(uris):\n",
    "    try:\n",
    "        response = spotify.audio_features(uris[start:(100+start)])\n",
    "        small_response = [{key:track[key] for key in track.keys() - keys_to_remove} for track in response]\n",
    "        audio_features.extend(small_response)\n",
    "    except AttributeError:\n",
    "        print(\"AttributeError\")\n",
    "        print(\"Start:\", start)\n",
    "    start += 100\n",
    "    if start % 1000 == 0: print(start)\n",
    "\n",
    "audio_df = pd.DataFrame(audio_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('uris_10.pickle', 'wb') as handle:\n",
    "    pickle.dump(uris, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('audio_features.pickle', 'wb') as handle:\n",
    "    pickle.dump(audio_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering songs together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(uri_input, uri_expected, test_size=.2, random_state=431)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170089\n",
      "170089\n"
     ]
    }
   ],
   "source": [
    "# Scale the features in audio_df to mean=0 and variance=1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "audio_scaled = ss.fit_transform(audio_df)\n",
    "\n",
    "print(len(uris))\n",
    "print(len(audio_scaled))\n",
    "\n",
    "audio_dict = {}\n",
    "for i in range(len(uris)):\n",
    "    audio_dict[uris[i]] = audio_scaled[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster songs and build dict with list of URIs for each cluster\n",
    "n_clusters = 75\n",
    "km_songs = KMeans(n_clusters=n_clusters)\n",
    "song_clusters = km_songs.fit_predict(audio_scaled)\n",
    "\n",
    "cluster_to_songs, song_to_cluster = {}, {}\n",
    "for i, cluster_num in enumerate(song_clusters):\n",
    "    if cluster_num not in cluster_to_songs:\n",
    "        cluster_to_songs[cluster_num] = []\n",
    "        \n",
    "    cluster_to_songs[cluster_num].append(uris[i])\n",
    "    song_to_cluster[uris[i]] = cluster_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClusterModel:\n",
    "    def __init__(self, cluster_to_song, song_to_cluster, audio_dict=None, n_clusters=20, K=25):\n",
    "        self.name = 'cluster_model'\n",
    "        self.n_clusters = n_clusters\n",
    "        self.cluster_to_song = cluster_to_song\n",
    "        self.song_to_cluster = song_to_cluster\n",
    "        self.K = K\n",
    "        self.audio_dict = audio_dict\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for playlist in X:\n",
    "            clusters = [self.song_to_cluster[song] for song in playlist if song in self.song_to_cluster]\n",
    "            unique, counts = np.unique(clusters, return_counts=True)\n",
    "            max_cluster_id = unique[np.argmax(counts)]\n",
    "            max_cluster = self.cluster_to_song[max_cluster_id]\n",
    "            try:\n",
    "                predicted = np.random.choice(max_cluster, size=500, replace=False)\n",
    "            except ValueError:\n",
    "                predicted = max_cluster\n",
    "            predictions.append(predicted)\n",
    "        return predictions\n",
    "    \n",
    "    def predict2(self, X):\n",
    "        predictions = []\n",
    "        for playlist in X:\n",
    "            clusters = [self.song_to_cluster[song] for song in playlist if song in self.song_to_cluster]\n",
    "            unique, counts = np.unique(clusters, return_counts=True)\n",
    "            predicted = []\n",
    "            for cl, count in zip(unique, counts):\n",
    "                size = count * (500 // self.K)\n",
    "                cluster = self.cluster_to_song[cl]\n",
    "                preds = np.random.choice(cluster, size=size, replace=False)\n",
    "                predicted.extend(preds)\n",
    "            predictions.append(predicted)\n",
    "        return predictions\n",
    "    \n",
    "    def predict3(self, X):\n",
    "        assert(self.audio_dict is not None)\n",
    "        predictions = []\n",
    "        for playlist in X:\n",
    "            clusters = [self.song_to_cluster[song] for song in playlist if song in self.song_to_cluster]\n",
    "            unique, counts = np.unique(clusters, return_counts=True)\n",
    "            max_cluster_id = unique[np.argmax(counts)]\n",
    "            max_cluster = self.cluster_to_song[max_cluster_id]\n",
    "            \n",
    "            avg_feat = self.get_average_features(playlist)\n",
    "            distances = [(uri, self.distance(avg_feat, self.audio_dict[uri])) for uri in max_cluster]\n",
    "            distances.sort(key=lambda tup: tup[1])\n",
    "            \n",
    "            predictions.append([uri for uri, _ in distances[:500]])\n",
    "        return predictions\n",
    "    \n",
    "    def get_average_features(self, playlist):\n",
    "        average_features = None\n",
    "        for uri in playlist:\n",
    "            features = self.audio_dict[uri]\n",
    "            if average_features is None:\n",
    "                average_features = features\n",
    "            else:\n",
    "                average_features = average_features + features\n",
    "        average_features = average_features / len(playlist)\n",
    "        return average_features\n",
    "    \n",
    "    def distance(self, audio1, audio2):\n",
    "        distance = np.sqrt(np.sum((audio1 - audio2) ** 2.0))\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Precision: 0.011361250312167193, NCDG: 0.00615822178764299, RSC: 40.774\n"
     ]
    }
   ],
   "source": [
    "cm = ClusterModel(cluster_to_songs, song_to_cluster, audio_dict=audio_dict)\n",
    "cm.fit(X_train_c, y_train_c)\n",
    "cm_output = cm.predict3(X_test_c)\n",
    "evaluate_model(cm_output, y_test_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first predict method (just 500 from the most common cluster) does a little better than the second predict method (try to mimic distribution). Probably because already a low success rate so just picking less common clusters makes it worse. And predict is significantly faster than predict2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNModel:\n",
    "    def __init__(self, audio_dict):\n",
    "        self.name = 'KNN'\n",
    "        self.audio_dict = audio_dict\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for playlist in X:\n",
    "            average_features = self.get_average_features(playlist)\n",
    "            distances = []\n",
    "            for uri in self.audio_dict.keys():\n",
    "                if uri not in playlist:\n",
    "                    d = self.distance(average_features, self.audio_dict[uri])\n",
    "                    distances.append((uri, d))\n",
    "            distances.sort(key=lambda tup: tup[1])\n",
    "            predictions.append([uri for uri, d in distances[:500]])\n",
    "        return predictions\n",
    "    \n",
    "    def distance(self, audio1, audio2):\n",
    "        distance = np.sqrt(np.sum((audio1 - audio2) ** 2.0))\n",
    "        return distance\n",
    "    \n",
    "    def get_average_features(self, playlist):\n",
    "        average_features = None\n",
    "        for uri in playlist:\n",
    "            features = self.audio_dict[uri]\n",
    "            if average_features is None:\n",
    "                average_features = features\n",
    "            else:\n",
    "                average_features = average_features + features\n",
    "        average_features = average_features / len(playlist)\n",
    "        return average_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-dd186d9ec06e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mknn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-166-37667c6f2ec9>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0muri\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muri\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplaylist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                     \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-166-37667c6f2ec9>\u001b[0m in \u001b[0;36mdistance\u001b[0;34m(self, audio1, audio2)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maudio2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda/envs/cs109/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   1795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m     \"\"\"\n\u001b[0;32m-> 1797\u001b[0;31m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1798\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keepdims'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "knn = KNNModel(audio_dict)\n",
    "knn.fit(X_train_c, y_train_c)\n",
    "knn_output = knn.predict(X_test_c)\n",
    "evaluate_model(knn_output, y_test_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model (Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Dense(hidden_size, input_dim=input_dim, activation='relu'))\n",
    "model1.add(Dense(hidden_size, activation='relu'))\n",
    "model1.add(Dense(output_dim, activation='linear'))\n",
    "\n",
    "model1.compile(optimizer='adam', loss='mae', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_history = model1.fit(X_train, y_train, batch_size=32, \n",
    "                            epochs=10, verbose=1, \n",
    "                            shuffle = True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "class Evaluator():\n",
    "    \"\"\"Superclass for evaluation functions\"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def evaluate(self, output, expected):\n",
    "        \"\"\"\n",
    "        Output will be the output of the model for some list of playlists\n",
    "        - Shape of (# playlists, 500)\n",
    "\n",
    "        Expected will be the held out songs from each playlist\n",
    "        - List of lists of various sizes\n",
    "\n",
    "        Note: Each \"song\" will be the unique spotify uri of a song\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "        \n",
    "class RPrecision(Evaluator):\n",
    "    \"\"\"\n",
    "    R-precision measures the number of held out songs correctly \n",
    "        retrieved by the model output \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        Evaluator.__init__(self, 'R-Precision')\n",
    "        \n",
    "    def evaluate(self, output, expected, return_all=False):\n",
    "    \n",
    "        def rprec_one(output_, expected_):\n",
    "            expected_size = len(expected_)\n",
    "            common_set = set(output_).intersection(set(expected_))\n",
    "            common_size = len(common_set)\n",
    "            if expected_size == 0 or common_size == 0:\n",
    "                return 0.0\n",
    "            return common_size / expected_size\n",
    "        \n",
    "        r_precs = [rprec_one(out, exp) for (out, exp) in zip(output, expected)]\n",
    "        if return_all:\n",
    "            return np.mean(r_precs), r_precs\n",
    "        return np.mean(r_precs)\n",
    "\n",
    "    \n",
    "class NDCG(Evaluator):\n",
    "    \"\"\"\n",
    "    Normalized discounted cumulative gain also takes into \n",
    "        account how the system ordered the suggestions\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        Evaluator.__init__(self, 'NDCG')\n",
    "        \n",
    "    def evaluate(self, output, expected):\n",
    "        \n",
    "        def ndcg_one(output_, expected_):\n",
    "            dcg, idcg = 0.0, 0.0\n",
    "            \n",
    "            if len(output_) == 0 or len(expected_) == 0:\n",
    "                return 0.0\n",
    "            \n",
    "            expected_ = set(expected_)\n",
    "            for i in range(len(output_)):\n",
    "                # Prediction DCG\n",
    "                if output_[i] in expected_:\n",
    "                    if i == 0:\n",
    "                        dcg += 1.0\n",
    "                    else:\n",
    "                        dcg += 1.0 / log2(i + 2.0)\n",
    "\n",
    "                if i < len(expected_):\n",
    "                    if i == 0:\n",
    "                        idcg += 1.0\n",
    "                    else:\n",
    "                        idcg += 1.0 / log2(i + 2.0)\n",
    "            \n",
    "            return dcg / idcg\n",
    "        \n",
    "        return np.mean([ndcg_one(out, exp) for (out, exp) in zip(output, expected)])\n",
    "        \n",
    "        \n",
    "class RSC(Evaluator):\n",
    "    \"\"\"\n",
    "    Recommended Song Clicks measures how many times a user\n",
    "    would have to click through the suggestions to find a song that \n",
    "    was a ground truth song\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        Evaluator.__init__(self, 'RSC')\n",
    "        \n",
    "    def evaluate(self, output, expected):\n",
    "        \n",
    "        def rsc_one(output_, expected_):\n",
    "            if len(output_) == 0 or len(expected_) == 0:\n",
    "                return 51\n",
    "            \n",
    "            output_len = len(output_)\n",
    "            expected_ = set(expected_)\n",
    "            for i in range(output_len):\n",
    "                if output_[i] in expected_:\n",
    "                    return i//10\n",
    "            return 51\n",
    "        \n",
    "        return np.mean([rsc_one(out, exp) for (out, exp) in zip(output, expected)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(output, expected):\n",
    "    r_prec = RPrecision().evaluate(output, expected)\n",
    "    ndcg = NDCG().evaluate(output, expected)\n",
    "    rsc = RSC().evaluate(output, expected)\n",
    "    print(f\"R-Precision: {r_prec}, NCDG: {ndcg}, RSC: {rsc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS 109",
   "language": "python",
   "name": "cs109"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
