{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS109a Final Project - Spotify Recommendation System\n",
    "Group \\#55: Nick Kochanek, Jack Connolly, Chris Jarrett, Andrew Soldini\n",
    "\n",
    "**Project Goal:**  \n",
    "Our goal for this project was to develop a system that could recommend reasonable songs to continue a playlist give a certain number of \"seed\" tracks. We formalized this task as giving a model a list of $K$ input songs (as Spotify uris) and having the model output $500$ suggested uris (ideally ranked by relevance). This falls in line with the formal specifications for the Spotify RecSys challenge, and allows us to compare results and approaches with top teams there. As such, we decided to evaluate our models using the same metrics the contest was based on, which will be described further on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "import pickle\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in the data (Million Playlist Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After running into issues trying to pickle large objects (ie our graph), \n",
    "# It turns out that there's an issue in the pickle implementation. This stack overflow function \n",
    "# allows for easy saving of big objects \n",
    "# https://stackoverflow.com/questions/42653386/does-pickle-randomly-fail-with-oserror-on-large-files\n",
    "def save_as_pickled_object(obj, filepath):\n",
    "    \"\"\"\n",
    "    This is a defensive way to write pickle.write, allowing for very large files on all platforms\n",
    "    \"\"\"\n",
    "    max_bytes = 2**31 - 1\n",
    "    bytes_out = pickle.dumps(obj)\n",
    "    n_bytes = sys.getsizeof(bytes_out)\n",
    "    with open(filepath, 'wb') as f_out:\n",
    "        for idx in range(0, n_bytes, max_bytes):\n",
    "            f_out.write(bytes_out[idx:idx+max_bytes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is the code from 'build_network.py'\n",
    "\n",
    "# 14 is a lot (the biggest we were able to run) \n",
    "# Use only like < 5 to finish in a reasonable time\n",
    "NUMBER_OF_FILES_TO_USE = 10\n",
    "\n",
    "\"\"\"\n",
    "The code below builds the network\n",
    "It also builds relevant objects to use for the other models\n",
    "\"\"\"\n",
    "song_name_to_uri, uri_to_song_name = {}, {}\n",
    "track_to_artist_album, network = {}, {}\n",
    "\n",
    "track_codes = set()\n",
    "playlists, uri_input, uri_expected = [], [], []\n",
    "\n",
    "K = 10\n",
    "\n",
    "f_start = 1000\n",
    "f_end = 1999\n",
    "for i in range(NUMBER_OF_FILES_TO_USE): \n",
    "    data_path = 'large_files/'\n",
    "    # data_path = './mpd.v1/data/'\n",
    "    with open(data_path + 'mpd.slice.{}-{}.json'.format(f_start, f_end)) as f: \n",
    "        data = json.load(f)\n",
    "        \n",
    "    input_, expected = [], []\n",
    "    for playlist in data['playlists']:\n",
    "        playlist_dict = playlist.copy()\n",
    "        playlist_dict.pop('tracks', None)\n",
    "\n",
    "        for k, song in enumerate(playlist['tracks']): \n",
    "            track_name  = song['track_name']\n",
    "            track_uri = song['track_uri']\n",
    "            shared_songs = np.array([s['track_uri'] for s in playlist['tracks'] if s['track_uri'] != track_uri])\n",
    "                \n",
    "            if track_uri not in track_codes:\n",
    "                track_codes.add(track_uri)\n",
    "                track_to_artist_album[track_uri] = {'artist': song['artist_name'], 'album': song['album_name']}\n",
    "                uri_to_song_name[track_uri] = track_name\n",
    "            \n",
    "            if track_name not in song_name_to_uri: \n",
    "                song_name_to_uri[track_name] = track_uri\n",
    "\n",
    "            if track_uri not in network: \n",
    "                network[track_uri] = np.array(shared_songs)\n",
    "            else: \n",
    "                network[track_uri] = np.append(network[track_uri], np.array(shared_songs))\n",
    "                \n",
    "            if k < K:\n",
    "                input_.append(track_uri)\n",
    "            else:\n",
    "                expected.append(track_uri)\n",
    "                \n",
    "        playlists.append(playlist_dict)\n",
    "        uri_input.append(input_)\n",
    "        uri_expected.append(expected)\n",
    "                \n",
    "    print (\"done loading file\", i)             \n",
    "    f_start += 1000\n",
    "    f_end += 1000\n",
    "    \n",
    "    \n",
    "# Clean the network -> counts per song (normalized)\n",
    "print(\"Cleaning up the Network a bit\")\n",
    "for uri in network : \n",
    "    unique, counts = np.unique(network[uri], return_counts=True)\n",
    "    network[uri] = {'songs' : unique, 'counts': counts / np.sum(counts)}\n",
    "    \n",
    "    \n",
    "# Save all of the objects as pickles\n",
    "save_as_pickled_object(network, 'pickled_network.pickle')\n",
    "\n",
    "with open('songs_to_uri.pickle', 'wb') as f:\n",
    "    pickle.dump(song_name_to_uri, f)\n",
    "\n",
    "with open('uri_to_song.pickle', 'wb') as f:\n",
    "    pickle.dump(uri_to_song_name, f)\n",
    "\n",
    "with open('track_to_artist_album.pickle', 'wb') as f:\n",
    "    pickle.dump(track_to_artist_album, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting audio features from the Spotify API**\n",
    "This takes awhile - you can just load to saved pickles 'audio_features.pickle' and 'uris_10.pickle' below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "cid =\"1b81d49177e5464781a4957e5e0c1ae6\" \n",
    "secret = \"c444a35689e247f8b5f9830662bae244\" \n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret) \n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager) \n",
    "sp.trace=False \n",
    "\n",
    "uris = list(track_codes)\n",
    "spotify = spotipy.Spotify(auth='BQDuG3_3-tAv09LQlZKwYc-oodCcDdau9O-I-Ep_O6IK-Uqvc5S3FKwdr5qtVu5Kq1khJCwkeaR9PnQJjvL6fBRPWdjJ9H_KRoGCrSlMP5DjdcLMlWJybPF1VvJDuSwBpoxiLS_Qmr9R4z-RoDWDPNiZnlzCeJNxMMvLRg')\n",
    "\n",
    "keys_to_remove = [\"duration_ms\", \"type\", \"id\", \"uri\", \"track_href\", \"analysis_url\"]\n",
    "\n",
    "start = 0\n",
    "audio_features = []\n",
    "while start < len(uris):\n",
    "    response = sp.audio_features(uris[start:(100+start)])\n",
    "    small_response = []\n",
    "    for track in response:\n",
    "        if track is not None:\n",
    "            small_dict = {key:track[key] for key in track.keys() - keys_to_remove}\n",
    "        else:\n",
    "            print('here')\n",
    "            small_dict = {key:0.0 for key in response[0].keys() - keys_to_remove}\n",
    "        small_response.append(small_dict)\n",
    "\n",
    "    audio_features.extend(small_response)\n",
    "        \n",
    "    start += 100\n",
    "    if start % 1000 == 0: print(start)\n",
    "\n",
    "audio_df = pd.DataFrame(audio_features)\n",
    "\n",
    "\n",
    "# Save the pickles\n",
    "with open('uris_10.pickle', 'wb') as handle:\n",
    "    pickle.dump(uris, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('audio_features.pickle', 'wb') as handle:\n",
    "    pickle.dump(audio_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170380\n",
      "170380\n"
     ]
    }
   ],
   "source": [
    "# Load the pickles instead of rescraping\n",
    "with open('uris_10.pickle', 'rb') as f:    \n",
    "    uris = pickle.load(f)\n",
    "with open('audio_features.pickle', 'rb') as f:    \n",
    "    audio_features = pickle.load(f)\n",
    "        \n",
    "audio_df = pd.DataFrame(audio_features)\n",
    "\n",
    "print(len(uris))\n",
    "print(len(audio_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split:\n",
    "As well as scaling so KNN and KMeans is meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170380\n",
      "170380\n"
     ]
    }
   ],
   "source": [
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(uri_input, uri_expected, test_size=.2, random_state=41)\n",
    "\n",
    "# Scale the features in audio_df to mean=0 and variance=1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "audio_scaled = ss.fit_transform(audio_df)\n",
    "\n",
    "print(len(uris))\n",
    "print(len(audio_scaled))\n",
    "\n",
    "audio_dict = {}\n",
    "for i in range(len(uris)):\n",
    "    audio_dict[uris[i]] = audio_scaled[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and EDA\n",
    "The data sources we utilized in our explorations were the Million Playlist Dataset and the Spotify API. The MPD gave us the essential data to train models on subsets of playlists and evaluate the accuracy of our predictions. We used to Spotify API to get pre-computed audio features for songs, which allowed us to expore alternative model choices more in line with what we looked at in class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = list(track_counts.keys())\n",
    "counts = list(track_counts.values())\n",
    "\n",
    "num_files = 20\n",
    "percent_data = (num_files / 1000) * 100\n",
    "\n",
    "plt.plot(range(len(names)), counts)\n",
    "plt.xlabel('Songs')\n",
    "plt.ylabel('# of Times it Appears')\n",
    "plt.title(f'Counts for each song that appears in the first {percent_data}% of the data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# More graphs and charts, both for MPD and for Spotify audio features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "We explored a variety of different models and model types, but because the style of problem was different than those we studied in class, we were forced to explore different techniques than those we had seen. Our baseline models use a combination of KMeans Clustering and/or KNN, while the top two performing models are a Markov Walk on a Network and Collaborative Filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: Song Based KMeans Clustering and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster songs and build:\n",
    "# - dict with list of URIs for each cluster\n",
    "# - dict with each song mapped to its cluster\n",
    "n_clusters = 75\n",
    "km_songs = KMeans(n_clusters=n_clusters)\n",
    "song_clusters = km_songs.fit_predict(audio_scaled)\n",
    "\n",
    "cluster_to_songs, song_to_cluster = {}, {}\n",
    "for i, cluster_num in enumerate(song_clusters):\n",
    "    if cluster_num not in cluster_to_songs:\n",
    "        cluster_to_songs[cluster_num] = []\n",
    "        \n",
    "    cluster_to_songs[cluster_num].append(uris[i])\n",
    "    song_to_cluster[uris[i]] = cluster_num\n",
    "    \n",
    "# Save the pickles\n",
    "with open('cluster_to_songs.pickle', 'wb') as handle:\n",
    "    pickle.dump(cluster_to_songs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('song_to_cluster.pickle', 'wb') as handle:\n",
    "    pickle.dump(song_to_cluster, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:  \n",
    "This clustering model is very much a baseline for the other models. Intuitively, it clusters all songs then for each input of seed songs, finds an the 'closest' songs to those, in some way. They all use the Spotify API audio features to cluster and make predictions, relatively ignoring the MPD aside as input and output uris. The following class has three different predict methods, namely `predict`, `predict2`, and `predict3`. The first simply calculates the most populous cluster among the input data, then randomly samples 500 songs from that cluster. The second tries to match the distribution of input songs more closely, outputting the number of songs in the input per cluster scaled up for a total of 500. Finally, the last method uses the audio features even more, calculating the 'distance' of every song in the same cluster to the 'average' of the input songs, outputting the 500 songs closest to the average in order. Overall, these methods do fairly poorly at matching the held out songs, only retrieving relevant songs fairly rarely. The R-precision of these methods is in the range of 0.005-0.011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClusterModel:\n",
    "    def __init__(self, cluster_to_song, song_to_cluster, audio_dict=None, n_clusters=20, K=25):\n",
    "        self.name = 'cluster_model'\n",
    "        self.n_clusters = n_clusters\n",
    "        self.cluster_to_song = cluster_to_song\n",
    "        self.song_to_cluster = song_to_cluster\n",
    "        self.K = K\n",
    "        self.audio_dict = audio_dict\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for playlist in X:\n",
    "            clusters = [self.song_to_cluster[song] for song in playlist if song in self.song_to_cluster]\n",
    "            unique, counts = np.unique(clusters, return_counts=True)\n",
    "            max_cluster_id = unique[np.argmax(counts)]\n",
    "            max_cluster = self.cluster_to_song[max_cluster_id]\n",
    "            try:\n",
    "                predicted = np.random.choice(max_cluster, size=500, replace=False)\n",
    "            except ValueError:\n",
    "                predicted = max_cluster\n",
    "            predictions.append(predicted)\n",
    "        return predictions\n",
    "    \n",
    "    def predict2(self, X):\n",
    "        predictions = []\n",
    "        for playlist in X:\n",
    "            clusters = [self.song_to_cluster[song] for song in playlist if song in self.song_to_cluster]\n",
    "            unique, counts = np.unique(clusters, return_counts=True)\n",
    "            predicted = []\n",
    "            for cl, count in zip(unique, counts):\n",
    "                size = count * (500 // self.K)\n",
    "                cluster = self.cluster_to_song[cl]\n",
    "                preds = np.random.choice(cluster, size=size, replace=False)\n",
    "                predicted.extend(preds)\n",
    "            predictions.append(predicted)\n",
    "        return predictions\n",
    "    \n",
    "    def predict3(self, X):\n",
    "        assert(self.audio_dict is not None)\n",
    "        predictions = []\n",
    "        for playlist in X:\n",
    "            clusters = [self.song_to_cluster[song] for song in playlist if song in self.song_to_cluster]\n",
    "            unique, counts = np.unique(clusters, return_counts=True)\n",
    "            max_cluster_id = unique[np.argmax(counts)]\n",
    "            max_cluster = self.cluster_to_song[max_cluster_id]\n",
    "            \n",
    "            avg_feat = self.get_average_features(playlist)\n",
    "            distances = [(uri, self.distance(avg_feat, self.audio_dict[uri])) for uri in max_cluster]\n",
    "            distances.sort(key=lambda tup: tup[1])\n",
    "            \n",
    "            predictions.append([uri for uri, _ in distances[:500]])\n",
    "        return predictions\n",
    "    \n",
    "    def get_average_features(self, playlist):\n",
    "        average_features = None\n",
    "        for uri in playlist:\n",
    "            features = self.audio_dict[uri]\n",
    "            if average_features is None:\n",
    "                average_features = features\n",
    "            else:\n",
    "                average_features = average_features + features\n",
    "        average_features = average_features / len(playlist)\n",
    "        return average_features\n",
    "    \n",
    "    def distance(self, audio1, audio2):\n",
    "        distance = np.sqrt(np.sum((audio1 - audio2) ** 2.0))\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Precision: 0.0018587709057330732, NCDG: 0.2096052794652136, RSC: 0.108\n"
     ]
    }
   ],
   "source": [
    "cm = ClusterModel(cluster_to_songs, song_to_cluster, audio_dict=audio_dict)\n",
    "cm.fit(X_train_c, y_train_c)\n",
    "cm_output = cm.predict(X_test_c)\n",
    "evaluate_model(cm_output, y_test_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another baseline: Playlist Based KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Playlist Based KNN (Chris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filtering code here (Chris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Based Markov Model\n",
    "This model is a probabilistic one that builds up a network where each vertex represents a song and each edge represents two song sharing a playlist (where more shared playlists leads to higher weighting). Then for prediction, for each of the input $K$ songs, many one step random walks are taken, and the most popular songs that show up in these walks are then returned as a list of 500 song recommendations (after getting rid of duplicates that are already in the playlist). This model consistently performed the best of our models, although building up a large network takes a significant amount of time and space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Building code\n",
    "\n",
    "NETWORK_FILE_PATH = 'pickled_network.pickle'\n",
    "\n",
    "with open(NETWORK_FILE_PATH, 'rb') as f: \n",
    "    NETWORK = pickle.load(f)\n",
    "    \n",
    "def n_top_songs(playlist_songs, network, num_samples=4000, num_top_songs=100): \n",
    "    key_errors = 0\n",
    "    all_samples = np.array([])\n",
    "    for song_uri in playlist_songs: \n",
    "        try : \n",
    "            sample = np.random.choice(network[song_uri]['songs'], num_samples, p=network[song_uri]['counts'])\n",
    "            all_samples = np.append(all_samples, sample)\n",
    "        except KeyError: \n",
    "            key_errors += 1\n",
    "    \n",
    "    unique, counts = np.unique(all_samples, return_counts=True)\n",
    "    \n",
    "    counts = counts.astype(float) / np.sum(counts)\n",
    "    counted_samples = zip(unique, counts)\n",
    "    counted_samples = [sample for sample in counted_samples if sample[0] not in playlist_songs]\n",
    "    counted_samples = sorted(counted_samples, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    num_to_return = min(num_top_songs, len(counted_samples))\n",
    "\n",
    "    return counted_samples[:num_to_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_network_accuracy(train, test, network, num_predictions=500): \n",
    "    print (\"starting with {} songs, and trying to find {} songs\".format(len(train), len(test)))\n",
    "    preds = n_top_songs(train, network, num_top_songs = num_predictions)\n",
    "    preds = [p[0] for p in preds]\n",
    "    correct_ratio = len([x for x in preds if x in test])/(1. * len(test))\n",
    "    print(correct_ratio)\n",
    "    return correct_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "We decided to evaluate our models based on the same metrics used in the Spotify RecSys [contest rules](https://recsys-challenge.spotify.com/rules), namely R-Precision (RPrec), Normalized Discounted Cumulative Gain (NDCG), and Recommended Song Clicks (RSC). In the following definitions, $G$ is the set of ground truth tracks representing the held out songs from each playlist and $R$ is the ordered list of recommended songs returned by the recommendation system.\n",
    "\n",
    "* R-Precision: The metric counts \"number of retrieved relevant tracks divided by the number of known relevant tracks,\" rewarding the total number of retrieved relevant tracks, regardless of order.\n",
    "$$\\text{R-precision} = \\frac{\\left| G \\cap R_{1:|G|} \\right|}{|G|}$$\n",
    "\n",
    "* Normalized Discounted Cumulative Gain (NDCG): This metric takes into account the order of the returned songs, rewarding relevant songs placed higher in the returned list. It is calculated as Discounted Cumulative Gain (DCG), divided by the Ideal Discounted Cumulative Gain (IDCG), where the returned songs are ordered perfectly. That calculation looks like:\n",
    "$$DCG = rel_1 + \\sum_{i=2}^{|R|} \\frac{rel_i}{\\log_2 (i + 1)}$$\n",
    "$$IDCG = 1 + \\sum_{i=2}^{|G|} \\frac{1}{\\log_2 (i + 1)}$$\n",
    "$$NDCG = \\frac{DCG}{IDCG}$$\n",
    "\n",
    "* Recommended Songs Clicks (RSC): This measures how many \"clicks\" a Spotify user would need to find the first relevant song in the recommendations (the first song actually in the rest of the playlist $G$), where Spotify displays recommended songs in groups of 10. Therefore it's simply finding the first relevant song and returning its position in the list divided by 10 and truncated. Or more formally:\n",
    "$$\\text{clicks} = \\left\\lfloor \\frac{ \\arg\\min_i \\{ R_i\\colon R_i \\in G|\\} - 1}{10} \\right\\rfloor$$\n",
    "\n",
    "We have implemented these metrics in code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "class Evaluator():\n",
    "    \"\"\"Superclass for evaluation functions\"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def evaluate(self, output, expected):\n",
    "        \"\"\"\n",
    "        Output will be the output of the model for some list of playlists\n",
    "        - Shape of (# playlists, 500)\n",
    "\n",
    "        Expected will be the held out songs from each playlist\n",
    "        - List of lists of various sizes\n",
    "\n",
    "        Note: Each \"song\" will be the unique spotify uri of a song\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "        \n",
    "class RPrecision(Evaluator):\n",
    "    \"\"\"\n",
    "    R-precision measures the number of held out songs correctly \n",
    "        retrieved by the model output \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        Evaluator.__init__(self, 'R-Precision')\n",
    "        \n",
    "    def evaluate(self, output, expected, return_all=False):\n",
    "    \n",
    "        def rprec_one(output_, expected_):\n",
    "            expected_size = len(expected_)\n",
    "            common_set = set(output_).intersection(set(expected_))\n",
    "            common_size = len(common_set)\n",
    "            if expected_size == 0 or common_size == 0:\n",
    "                return 0.0\n",
    "            return common_size / expected_size\n",
    "        \n",
    "        r_precs = [rprec_one(out, exp) for (out, exp) in zip(output, expected)]\n",
    "        if return_all:\n",
    "            return np.mean(r_precs), r_precs\n",
    "        return np.mean(r_precs)\n",
    "\n",
    "    \n",
    "class NDCG(Evaluator):\n",
    "    \"\"\"\n",
    "    Normalized discounted cumulative gain also takes into \n",
    "        account how the system ordered the suggestions\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        Evaluator.__init__(self, 'NDCG')\n",
    "        \n",
    "    def evaluate(self, output, expected):\n",
    "        \n",
    "        def ndcg_one(output_, expected_):\n",
    "            dcg, idcg = 0.0, 0.0\n",
    "            \n",
    "            if len(output_) == 0 or len(expected_) == 0:\n",
    "                return 0.0\n",
    "            \n",
    "            expected_ = set(expected_)\n",
    "            for i in range(len(output_)):\n",
    "                # Prediction DCG\n",
    "                if output_[i] in expected_:\n",
    "                    if i == 0:\n",
    "                        dcg += 1.0\n",
    "                    else:\n",
    "                        dcg += 1.0 / log2(i + 2.0)\n",
    "\n",
    "                if i < len(expected_):\n",
    "                    if i == 0:\n",
    "                        idcg += 1.0\n",
    "                    else:\n",
    "                        idcg += 1.0 / log2(i + 2.0)\n",
    "            \n",
    "            return dcg / idcg\n",
    "        \n",
    "        return np.mean([ndcg_one(out, exp) for (out, exp) in zip(output, expected)])\n",
    "        \n",
    "        \n",
    "class RSC(Evaluator):\n",
    "    \"\"\"\n",
    "    Recommended Song Clicks measures how many times a user\n",
    "    would have to click through the suggestions to find a song that \n",
    "    was a ground truth song\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        Evaluator.__init__(self, 'RSC')\n",
    "        \n",
    "    def evaluate(self, output, expected):\n",
    "        \n",
    "        def rsc_one(output_, expected_):\n",
    "            if len(output_) == 0 or len(expected_) == 0:\n",
    "                return 51\n",
    "            \n",
    "            output_len = len(output_)\n",
    "            expected_ = set(expected_)\n",
    "            for i in range(output_len):\n",
    "                if output_[i] in expected_:\n",
    "                    return i//10\n",
    "            return 51\n",
    "        \n",
    "        return np.mean([rsc_one(out, exp) for (out, exp) in zip(output, expected)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(output, expected, title=''):\n",
    "    r_prec = RPrecision().evaluate(output, expected)\n",
    "    ndcg = NDCG().evaluate(output, expected)\n",
    "    rsc = RSC().evaluate(output, expected)\n",
    "    print(f\"{title}: R-Precision: {r_prec}, NCDG: {ndcg}, RSC: {rsc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of each model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_train_test_set(start, blocks = 1, n_train=10) : \n",
    "    \"\"\" evaluates on n 1000 playlist blocks beginning with file start = start\n",
    "    \"\"\"\n",
    "    f_start = start * 1000\n",
    "    f_end = start * 1000 + 999\n",
    "    train_songs = []\n",
    "    test_songs = []\n",
    "    for i in range(blocks): \n",
    "        path = 'large_files/'\n",
    "        # path = './mpd.v1/data/'\n",
    "        with open(path + 'mpd.slice.{}-{}.json'.format(f_start, f_end)) as f :\n",
    "            data = json.load(f)\n",
    "            \n",
    "            for playlist in data['playlists'] : \n",
    "                tracks = [t['track_uri'] for t in playlist['tracks']]\n",
    "                if len(tracks) > 10 * n_train: \n",
    "                    train = tracks[:n_train]\n",
    "                    test = tracks[n_train:]\n",
    "\n",
    "                    train_songs.append(train)\n",
    "                    test_songs.append(test)\n",
    "                        \n",
    "    return train_songs, test_songs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = build_train_test_set(17, blocks=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Cluster Model': cm,\n",
    "    'Network': NETWORK,\n",
    "}\n",
    "\n",
    "evaluate_network_accuracy(train, test, NETWORK)\n",
    "\n",
    "# for name, model in models.iteritems():\n",
    "#     output = model.predict(X_test_c)\n",
    "#     evaluate_model(output, expected, title=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions and Interpretations\n",
    "Overall, we have seen that the filtering and network models perform the best, significantly improving over the baseline models using nearest neighbor techniques. Our final models were comparable with some of the top models in the RecSys challenge, so we are very satisfied with our results. If we had more time and computing power, we would have liked to scale both of those models up larger, as they were both limited in terms of their size (the network was trained on about 14000 playlists and ended up being about 7GB while filtering was only able to handle about **HOW MANY PLAYLISTS**). Ideally, we would be able to utilize sklearn's suppoer for sparse matrices to scale up filtering, but we weren't able to finalize that. \n",
    "\n",
    "Music recommendation in general is a challenging problem, with millions of songs to choose from and a large variety of songs within. More complex techniques like deep RNNs and autoencoders seemed attractive at the beginning of the project, but ultimately weren't feasible for us to complete. This forced us to adapt and implement the fairly different models seen here. Overall, we feel confident in our model's ability to find relevant songs to continue and put together a great playlist."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS 109",
   "language": "python",
   "name": "cs109"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
